{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection With Machine Learning\n",
    "\n",
    "Sebagai manusia, kita bisa secara mudah mendeteksi bahasa terhadap kalimat, sebagai contoh perbedaan bahasa indonesia dan bahasa inggris. Project ini dapat mengklasifikasikan sebuah kalimat menggunakan bahasa. Google Translate merupakan salah satu translator bahasa yang paling banyak digunakan didunia. Jadi, diproject kita kali ini akan membuat sebuah model machine learning untuk mendeteksi bahasa.\\\n",
    "Sebenarnya sudah banyak model yang digunakan untuk mendeteksi bahasa. Lebih banyak data terhadap bahasa maka akurasi terhadap model akan semakin baik. Dataset ini berasal dari kaggle yang berisi seputar 22 bahasa popouler yang berisi 1000 kalimat setiap bahasa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library\n",
    "\n",
    "Kita akan mengimport beberapa library yang diperlukan untuk membuat model machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # berfungsi untuk membaca file csv\n",
    "import numpy as np # berfungsi untuk melakukan operasi vektor dan matriks\n",
    "from sklearn.feature_extraction.text import CountVectorizer # berfungsi untuk melakukan vektorisasi pada kalimat\n",
    "from sklearn.model_selection import train_test_split # berfungsi untuk membagi data menjadi data training dan data testing\n",
    "from sklearn.naive_bayes import MultinomialNB # berfungsi untuk melakukan klasifikasi dengan menggunakan algoritma Naive Bayes khusus untuk multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membaca Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>müller mox figura centralis circulorum doctoru...</td>\n",
       "      <td>Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>برقی بار electric charge تمام زیرجوہری ذرات کی...</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch\n",
       "5  エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...  Japanese\n",
       "6  tsutinalar i̇ngilizce tsuutina kanadada albert...   Turkish\n",
       "7  müller mox figura centralis circulorum doctoru...     Latin\n",
       "8  برقی بار electric charge تمام زیرجوہری ذرات کی...      Urdu\n",
       "9  シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...  Japanese"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan**\\\n",
    "Kita bisa lihat diatas untuk 10 data pertama terdapat beberapa text dengan bahasa tertentu misalnya **klement gottwaldi surnukeha palsameeriti ning ...** dengan bahasa\t**Estonian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengecek apakah ada data yang kosong\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengecek jumlah data pada setiap kelas\n",
    "\n",
    "data['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan**\\\n",
    "Bisa kita lihat diatas bahwa jumlah kelas terdiri dari 22 bahasa atau kelas dengan jumlah data masing-masing kelas adalah 1000. Total keseluruhan data ialah 22000. Kita dapat membuat model machine learning dengan jumlah dataset sebesar ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Membuat Model\n",
    "\n",
    "Kita akan membagikan data kedalam set data pelatihan dan set data pengujian serta variabel X sebagai atribut text dan variabel y sebagai atribut language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14740, 277720)\n",
      "(7260, 277720)\n",
      "(14740,)\n",
      "(7260,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data['Text']) # mengambil data teks lalu dijadikan array\n",
    "y = np.array(data['language']) # mengambil data kelas lalu dijadikan array\n",
    "\n",
    "cv = CountVectorizer() # membuat objek CountVectorizer\n",
    "X = cv.fit_transform(X) # melakukan vektorisasi pada data teks\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) # membagi data menjadi data training dan data testing dengan perbandingan 67:33\n",
    "\n",
    "print(X_train.shape) # mengecek dimensi X data training\n",
    "print(X_test.shape) # mengecek dimensi X data testing\n",
    "print(y_train.shape) # mengecek dimensi y data training\n",
    "print(y_test.shape) # mengecek dimensi y data testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan**\n",
    "Bisa kita lihat diatas untuk data training dan testing sebagai berikut\n",
    "1. Jumlah Data Training : 14740\n",
    "2. Jumlah Data Testing : 7260\n",
    "\n",
    "Sedangkan untuk jumlah atribut ketika dilakukan vektorasasi adalah **277720** atau dengan kata lain ada sekitar 277720 kata yang terbentuk dari dataset ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kenapa kita menggunakan **MultinomialNaiveBayes** bukan **BernoulliNaiveBayes** seperti pada project sebelumnya, jawabanya cukup simple. project ini akan melakukan klasifikasi terhadap beberapa kelas bahasa atau dengan kata lain klasifikasi untuk multiclass sedangkan BernouliNaiveBayes khusus untuk klasifikasi biner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skor Akurasi : 0.953168044077135\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Skor Akurasi : {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita bisa lihat diatas bahwa untuk model machine learning yang kita buat menghasilkan akurasi **0.953168044077135** atau 95% dapat mendeteksi terhadap 22 bahasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Prediksi Bahasa : ['Indonesian']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Masukkan Kalimat : \") # berfungsi untuk meminta inputan dari user\n",
    "data = cv.transform([user]).toarray() # melakukan vektorisasi pada inputan user\n",
    "output = model.predict(data) # melakukan prediksi\n",
    "print(f'Hasil Prediksi Bahasa : {output}') # berfungsi untuk menampilkan hasil prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kesimpulan\n",
    "\n",
    "Dari kalimat masukkan dari user **Saya sekarang sedang mengerjakan project** berhasil dideteksi oleh model machine learning menggunakan bahasa **Indonesia**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f8efe6f8c472f9f769de94b02d12f378fc577fc6207da273e460a2116b30721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
