{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Sarcasm Detecion With Machine Learning\n",
    "\n",
    "Sarkasme secara harfiah berarti majas kata-kata yang dapat menyakiti orang lain dalam bentuk sindiran maupun ejekan. Project ini merupakan salah satu pemrosesan bahasa alami atau yang dikenal dengan NLP dan merupakan sebuah task untuk binary classification\\.\n",
    "\n",
    "Jadi kita akan membuat sebuah machine learning model (hasil belajar) untuk dapat mendeteki apakah sebuah kalimat mengandung sarkasme atau tidak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import\n",
    "\n",
    "Import beberapa library yang dibutuuhkan untuk menyelesaikan tugas deteksi sarkasme dengan machine learning menggunakan python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # Berfungi untuk mengolah data numerik\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Berfungsi untuk menghitung jumlah kemunculan kata\n",
    "from sklearn.model_selection import train_test_split # Berfungsi untuk membagi data menjadi data latih dan data uji\n",
    "from sklearn.naive_bayes import BernoulliNB # Berfungi untuk mengklasifikasikan data (khusus untuk data yang bernilai boolean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membaca data\n",
    "\n",
    "Disini kita memiliki sebuah dataset dengan nama file sarcasm.json. jadi, kita perlu membaca file dot json dengan bantuan pandas sebagai I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/advancing...</td>\n",
       "      <td>advancing the world's women</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/how-meat-...</td>\n",
       "      <td>the fascinating case for eating lab-grown meat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/boxed-col...</td>\n",
       "      <td>this ceo will send your kids to school, if you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://politics.theonion.com/top-snake-handle...</td>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/fridays-m...</td>\n",
       "      <td>friday's morning email: inside trump's presser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "5  https://www.huffingtonpost.com/entry/advancing...   \n",
       "6  https://www.huffingtonpost.com/entry/how-meat-...   \n",
       "7  https://www.huffingtonpost.com/entry/boxed-col...   \n",
       "8  https://politics.theonion.com/top-snake-handle...   \n",
       "9  https://www.huffingtonpost.com/entry/fridays-m...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  \n",
       "5                        advancing the world's women             0  \n",
       "6     the fascinating case for eating lab-grown meat             0  \n",
       "7  this ceo will send your kids to school, if you...             0  \n",
       "8  top snake handler leaves sinking huckabee camp...             1  \n",
       "9  friday's morning email: inside trump's presser...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('sarcasm.json', lines=True) # Membaca data dari file json\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Data dalam Dataset Ini : 26709\n"
     ]
    }
   ],
   "source": [
    "print(f'Jumlah Data dalam Dataset Ini : {len(data)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Catatan*\n",
    "1. Dataset ini memiliki 3 atribut antara lain (article_link, headline, is_sarcastic)\n",
    "2. article_link dan headline sebagai predictor atau feature\n",
    "3. is_sarcastic sebagai class atau outcome\n",
    "\n",
    "atribut **is_sarcastic** memiliki kelas yang digunakan untuk mendeteksi apakah sebuah kalimat mengandung sarkasme atau tidak. Dalam atribut ini mengandung nilai 1 berarti mengandung sarkasme atau 0 sebaliknya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Preprocessing\n",
    "\n",
    "Kita akan melakukan perubahan value label yang semula 1 menjadi **sarkasme** dan 0 menjadi **bukan sarkasme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>Bukan Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>Bukan Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>Bukan Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/advancing...</td>\n",
       "      <td>advancing the world's women</td>\n",
       "      <td>Bukan Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/how-meat-...</td>\n",
       "      <td>the fascinating case for eating lab-grown meat</td>\n",
       "      <td>Bukan Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/boxed-col...</td>\n",
       "      <td>this ceo will send your kids to school, if you...</td>\n",
       "      <td>Bukan Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://politics.theonion.com/top-snake-handle...</td>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>Sarkasme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/fridays-m...</td>\n",
       "      <td>friday's morning email: inside trump's presser...</td>\n",
       "      <td>Bukan Sarkasme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "5  https://www.huffingtonpost.com/entry/advancing...   \n",
       "6  https://www.huffingtonpost.com/entry/how-meat-...   \n",
       "7  https://www.huffingtonpost.com/entry/boxed-col...   \n",
       "8  https://politics.theonion.com/top-snake-handle...   \n",
       "9  https://www.huffingtonpost.com/entry/fridays-m...   \n",
       "\n",
       "                                            headline    is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...  Bukan Sarkasme  \n",
       "1  the 'roseanne' revival catches up to our thorn...  Bukan Sarkasme  \n",
       "2  mom starting to fear son's web series closest ...        Sarkasme  \n",
       "3  boehner just wants wife to listen, not come up...        Sarkasme  \n",
       "4  j.k. rowling wishes snape happy birthday in th...  Bukan Sarkasme  \n",
       "5                        advancing the world's women  Bukan Sarkasme  \n",
       "6     the fascinating case for eating lab-grown meat  Bukan Sarkasme  \n",
       "7  this ceo will send your kids to school, if you...  Bukan Sarkasme  \n",
       "8  top snake handler leaves sinking huckabee camp...        Sarkasme  \n",
       "9  friday's morning email: inside trump's presser...  Bukan Sarkasme  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_sarcastic'] = data['is_sarcastic'].map({0: 'Bukan Sarkasme', 1: 'Sarkasme'}) # Mengubah nilai 0 menjadi 'Bukan Sarkasme' dan nilai 1 menjadi 'Sarkasme'\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Melatih Model Machine Laerning\n",
    "\n",
    "Dalam dataset ini memiliki 3 atribut yang sudah dijelaskan sebelumnya, kita hanya perlu menggunakan 2 kolom dalam kasus NLP yakni **headline** sebagai variabel X dan **is_sarcastic** sebagai variabel y, lalu kita akan membagi set data untuk uji sebesar 20% dan set data latih sebesar 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21367, 25292)\n",
      "(5342, 25292)\n",
      "(21367,)\n",
      "(5342,)\n"
     ]
    }
   ],
   "source": [
    "data = data[['headline', 'is_sarcastic']] # Mengambil data yang hanya berisi kolom 'headline' dan 'is_sarcastic'\n",
    "X = np.array(data['headline']) # Mengambil data dari kolom 'headline' dan menyimpannya ke dalam variabel X\n",
    "y = np.array(data['is_sarcastic']) # Mengambil data dari kolom 'is_sarcastic' dan menyimpannya ke dalam variabel y\n",
    "\n",
    "\n",
    "cv = CountVectorizer() # Membuat objek CountVectorizer\n",
    "X = cv.fit_transform(X) # Mengubah data menjadi vektor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # Memisahkan data menjadi data latih dan data uji masing-masing 80% dan 20%\n",
    "\n",
    "print(X_train.shape) # Menampilkan X jumlah data latih\n",
    "print(X_test.shape) # Menampilkan X jumlah data uji\n",
    "print(y_train.shape) # Menampilkan y jumlah data latih\n",
    "print(y_test.shape) # Menampilkan y jumlah data uji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan**\n",
    "Dalam melatih model machine learning, disini kita menggunakan salah satu varian dalam algoritma naive bayes yakni **Bernoulli Naive Bayes** untuk mendeteksi kalimat sarkasme atau tidak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8921)\t1\n",
      "  (0, 24096)\t1\n",
      "  (0, 21583)\t1\n",
      "  (0, 4379)\t1\n",
      "  (0, 21848)\t1\n",
      "  (0, 15951)\t1\n",
      "  (0, 19883)\t1\n",
      "  (0, 2530)\t1\n",
      "  (0, 4514)\t1\n",
      "  (0, 8863)\t1\n",
      "  (0, 14378)\t1\n",
      "  (0, 20307)\t1\n",
      "  (1, 8863)\t1\n",
      "  (1, 22582)\t1\n",
      "  (1, 19265)\t1\n",
      "  (1, 18943)\t1\n",
      "  (1, 3752)\t1\n",
      "  (1, 23843)\t1\n",
      "  (1, 22827)\t1\n",
      "  (1, 15869)\t1\n",
      "  (1, 22661)\t1\n",
      "  (1, 17016)\t1\n",
      "  (1, 14633)\t1\n",
      "  (1, 2371)\t1\n",
      "  (1, 1117)\t1\n",
      "  :\t:\n",
      "  (26704, 9026)\t1\n",
      "  (26704, 8234)\t1\n",
      "  (26704, 17022)\t1\n",
      "  (26704, 14644)\t1\n",
      "  (26705, 1054)\t1\n",
      "  (26705, 2351)\t1\n",
      "  (26705, 128)\t1\n",
      "  (26705, 10599)\t1\n",
      "  (26706, 1117)\t1\n",
      "  (26706, 15510)\t1\n",
      "  (26706, 18657)\t1\n",
      "  (26707, 1947)\t1\n",
      "  (26707, 21977)\t1\n",
      "  (26707, 11882)\t1\n",
      "  (26707, 18028)\t1\n",
      "  (26707, 857)\t1\n",
      "  (26707, 2902)\t1\n",
      "  (26707, 22327)\t1\n",
      "  (26707, 440)\t1\n",
      "  (26708, 8863)\t1\n",
      "  (26708, 22582)\t1\n",
      "  (26708, 147)\t1\n",
      "  (26708, 9495)\t1\n",
      "  (26708, 9730)\t1\n",
      "  (26708, 8842)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ketika kita melatih menggunakan **Count Vectorizer** secara otomatis akan menghasilkan sebuah matrix sparse, kita ambil salah satu contoh data point/document/baris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"former versace store clerk sues over secret 'black code' for minority shoppers\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headline'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diatas merupakan document pada baris pertama dengan teks headline **former versace store clerk sues over secret 'black code' for minority shoppers**. Kalimat ini akan diubah secara otomatis menggunakan count vetorizer dengan memisahkan setiap kata kedalam atribut yang secara otomatis sudah ditentukan seperti dibawah ini\n",
    "\n",
    "\n",
    "|8921  |24096   |21583  |4379   |21848  |15951  |19883  |2530   |4514   |8863   |14378   |20307   |\n",
    "| :--- | :----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----:  |   ---: |\n",
    "|former|versace |store  |clerk  |sues   |over   |secret |black  |code   |for    |minority|shoppers|\n",
    "\n",
    "Bisa kita lihat disini bahwa atribut kolom 8921 itu berisi kata **former**\n",
    "\n",
    "**Catatan : Perhatikan Output Variabel X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440658929239985\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB() # Membuat objek BernoulliNB\n",
    "model.fit(X_train, y_train) # Melatih model dengan data latih\n",
    "print(model.score(X_test, y_test)) # Menampilkan akurasi model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diatas bisa kita lihat bahwa akurasi yang dihasilkan pada model adlah 0.8440658929239985 atau **84%** dan dengan kata lain model machine learning ini hanya mampu mendeteksi bahasa mengandung sarkasme atau tidak sebesar **84%** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pengujian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Prediksi :  ['Bukan Sarkasme']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Masukkan Teks : \")\n",
    "data = cv.transform([user]).toarray() # Mengubah data teks diatas menjadi vektor\n",
    "output = model.predict(data) # Memprediksi data teks diatas\n",
    "print(\"Hasil Prediksi : \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada pengujian model dengan memprediksi teks antara lain\n",
    "1. You bastard (Hasil : Mengandunug Sarkasme)\n",
    "2. You are very diligent (Hasil : Bukan Sarksme)\n",
    "\n",
    "Thanks ðŸ˜ŠðŸ˜ŠðŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f8efe6f8c472f9f769de94b02d12f378fc577fc6207da273e460a2116b30721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
